{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_i1q1TWG9zH"
   },
   "source": [
    "# Deep Crossentropy method\n",
    "\n",
    "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games. __Please make sure you're done with tabular crossentropy method from the previous notebook.__\n",
    "\n",
    "![img](https://watanimg.elwatannews.com/old_news_images/large/249765_Large_20140709045740_11.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "t4CJ1sRyG9zJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: ../xvfb: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
    "    !touch .setup_complete\n",
    "\n",
    "# This code creates a virtual display to draw game images on.\n",
    "# It will have no effect if your machine has a monitor.\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "C2xd5vPwPVCb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium[classic_control,toy_text] in /Users/luc/Library/Python/3.11/lib/python/site-packages (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/homebrew/lib/python3.11/site-packages (from gymnasium[classic_control,toy_text]) (1.24.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/luc/Library/Python/3.11/lib/python/site-packages (from gymnasium[classic_control,toy_text]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/luc/Library/Python/3.11/lib/python/site-packages (from gymnasium[classic_control,toy_text]) (4.7.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/luc/Library/Python/3.11/lib/python/site-packages (from gymnasium[classic_control,toy_text]) (0.0.4)\n",
      "Requirement already satisfied: pygame>=2.1.3 in /Users/luc/Library/Python/3.11/lib/python/site-packages (from gymnasium[classic_control,toy_text]) (2.4.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: joblist in /Users/luc/Library/Python/3.11/lib/python/site-packages (2.0.3)\n",
      "Requirement already satisfied: w3lib in /Users/luc/Library/Python/3.11/lib/python/site-packages (from joblist) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Install gymnasium if you didn't\n",
    "!pip install \"gymnasium[toy_text,classic_control]\"\n",
    "!pip install joblist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AntLeagueEnv __init__\n"
     ]
    }
   ],
   "source": [
    "from springchallenge2023.envs.ant_league import AntLeagueEnv\n",
    "from springchallenge2023.wrappers.MultipleStepWrapper import MultipleStepWrapper\n",
    "from springchallenge2023.wrappers.EncodeCellType import EncodeCellType\n",
    "from springchallenge2023.wrappers.ComputeEggCrystalRatio import ComputeEggCrystalRatio\n",
    "from springchallenge2023.wrappers.Normalize import Normalize\n",
    "from springchallenge2023.wrappers.BeaconAction import BeaconAction\n",
    "\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from gymnasium.wrappers import FlattenObservation\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"springchallenge2023/AntLeague-v0\", max_episode_steps=10000).env\n",
    "env = BeaconAction(env)                            # obs (15, 5)  int,   action (15,) float\n",
    "env = EncodeCellType(env)                          # obs (15, 11) int,   action (15,)\n",
    "env = ComputeEggCrystalRatio(env)                  # { map = obs (15, 13) float, ratio = float }, action (31,)\n",
    "env = Normalize(env)                               # { map = obs (15, 13) float, ratio = float }, action (31,)\n",
    "env = FlattenObservation(env)                      # obs (167, ) float, action (15,)\n",
    "seed = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_2zbc7ahG9zK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state vector dim = 167\n",
      "n_actions = Box(0.0, 1.0, (15,), float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env.reset(seed=seed)\n",
    "n_actions = env.action_space\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "# plt.imshow(env.render())\n",
    "print(\"state vector dim =\", state_dim)\n",
    "print(\"n_actions =\", n_actions)\n",
    "\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z72_alhdG9zK"
   },
   "source": [
    "# Neural Network Policy\n",
    "\n",
    "For this assignment we'll utilize the simplified neural network implementation from __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Here's what you'll need:\n",
    "\n",
    "* `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probability of :actions: from :states:\n",
    "* `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape __[len(states), n_actions]__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wLItY4unG9zL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env0:  (122,)\n",
      "aenv0:  [array([0.        , 1.        , 0.        , 0.        , 0.2       ,\n",
      "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.90909091,\n",
      "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
      "       0.        , 0.        , 0.90909091, 0.        , 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
      "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
      "       0.        , 0.        , 1.        , 1.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.05429864, 1.        ])]\n",
      "n_actions:  Box(0.0, 1.0, (15,), float64)\n",
      "act0:  [0.18651417 0.27849499 0.68479797 0.13818037 0.31169693 0.46981316\n",
      " 0.82769144 0.68818375 0.97879827 0.10290738 0.1037904  0.86481438\n",
      " 0.74585294 0.8563441  0.53758926]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(200, 100), learning_rate=&#x27;invscaling&#x27;,\n",
       "             max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(200, 100), learning_rate=&#x27;invscaling&#x27;,\n",
       "             max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(200, 100), learning_rate='invscaling',\n",
       "             max_iter=1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "agent = MLPRegressor(hidden_layer_sizes=(200, 100),\n",
    "                     activation='relu',\n",
    "                     max_iter=1000,\n",
    "                     solver='adam',\n",
    "                     alpha=0.0001,\n",
    "                     learning_rate='invscaling')\n",
    "\n",
    "\n",
    "env0=env.reset(seed=seed)[0]\n",
    "act0 = n_actions.sample()\n",
    "print(\"env0: \", env0.shape)\n",
    "print(\"aenv0: \", [env0])\n",
    "print(\"n_actions: \", n_actions)\n",
    "print(\"act0: \", act0)\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env0], [act0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "filename = \"sprinchallenge2023_mplcregressor.joblib\"\n",
    "\n",
    "# load model\n",
    "agent = joblib.load(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eyFS3oUmG9zL"
   },
   "outputs": [],
   "source": [
    "def generate_session(env, agent, t_max=10000):\n",
    "    \"\"\"\n",
    "    Play a single game using agent neural network.\n",
    "    Terminate when game finishes or after :t_max: steps\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s, _ = env.reset(seed=seed)\n",
    "\n",
    "    for t in range(t_max):\n",
    "\n",
    "        # print(\"action_space \", env.action_space.n)\n",
    "        # print(\"state \",s)\n",
    "        # print(\"n_actions\", n_actions)\n",
    "\n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "        act = agent.predict(s.reshape(1, -1)).reshape(n_actions.shape,)\n",
    "\n",
    "        # print(\"act \",act)\n",
    "        # print(\"act.shape \",act.shape)\n",
    "        # print(\"n_actions.shape \",n_actions.shape)\n",
    "        assert act.shape == n_actions.shape, \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "\n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        # a = np.random.choice(range(n_actions), p=probs)\n",
    "        # ^-- hint: try np.random.choice\n",
    "\n",
    "        new_s, r, terminated, truncated, _ = env.step(act)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(act)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    return states, actions, total_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4xgrTCgJG9zL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states: [[0.         1.         0.         ... 0.         0.05429864 1.        ]\n",
      " [0.         1.         0.         ... 0.         0.05763689 1.        ]\n",
      " [0.         1.         0.         ... 0.         0.05763689 1.        ]\n",
      " ...\n",
      " [0.         1.         0.         ... 0.         1.42857143 1.        ]\n",
      " [0.         1.         0.         ... 0.         1.2244898  1.        ]\n",
      " [0.         1.         0.         ... 0.         1.2        1.        ]]\n",
      "actions: [array([ 3.98999304e-01,  4.00351906e-01, -1.36142276e-03,  1.09974226e+00,\n",
      "        3.98918290e-01,  3.98889821e-01,  8.36201226e-01,  6.61971336e-03,\n",
      "        1.23733967e-04,  1.06627922e+00,  4.09650814e-02, -1.47091233e-03,\n",
      "        8.02209476e-02,  3.05939437e-02, -6.36464258e-02]), array([ 0.39295863,  0.40066563,  0.00831168,  0.97467114,  0.39174147,\n",
      "        0.4053021 ,  0.84901697, -0.05979701, -0.00247245,  0.96046878,\n",
      "        0.01849777,  0.09259751,  0.07148889, -0.00165748, -0.10286654]), array([ 0.39255177,  0.40139268,  0.00629865,  0.97517841,  0.39195782,\n",
      "        0.40616485,  0.84991451, -0.05751435, -0.0024929 ,  0.95914082,\n",
      "        0.01938891,  0.09222908,  0.07185493, -0.00280545, -0.10428599]), array([ 0.39255177,  0.40139268,  0.00629865,  0.97517841,  0.39195782,\n",
      "        0.40616485,  0.84991451, -0.05751435, -0.0024929 ,  0.95914082,\n",
      "        0.01938891,  0.09222908,  0.07185493, -0.00280545, -0.10428599]), array([ 0.3981781 ,  0.39929527, -0.00699298,  1.03609465,  0.40002134,\n",
      "        0.39514383,  0.86194861, -0.06497028, -0.00202023,  1.08041102,\n",
      "        0.0084296 ,  0.01278445,  0.08222918,  0.01037414, -0.08758778]), array([ 0.40022511,  0.40346483, -0.00422834,  1.04225768,  0.40038567,\n",
      "        0.39776233,  0.86471534, -0.06666842, -0.00164301,  1.08213457,\n",
      "        0.00689878,  0.01661064,  0.08160485,  0.01120168, -0.08336546]), array([ 0.40022511,  0.40346483, -0.00422834,  1.04225768,  0.40038567,\n",
      "        0.39776233,  0.86471534, -0.06666842, -0.00164301,  1.08213457,\n",
      "        0.00689878,  0.01661064,  0.08160485,  0.01120168, -0.08336546]), array([ 0.39801366,  0.39956332,  0.00154524,  1.02376011,  0.39700765,\n",
      "        0.39458342,  0.88072035, -0.10930062, -0.00161166,  0.99410667,\n",
      "        0.03325318,  0.10182692,  0.14052192, -0.01066399, -0.11092242]), array([ 3.98864794e-01,  4.00747469e-01, -2.38450561e-03,  1.02751557e+00,\n",
      "        3.97835187e-01,  3.99797364e-01,  8.83186369e-01, -1.05282603e-01,\n",
      "        9.65869388e-04,  9.98822456e-01,  3.17188411e-02,  9.77762769e-02,\n",
      "        1.37526363e-01, -1.16112026e-02, -1.10561342e-01]), array([ 0.39784732,  0.39431273, -0.0026304 ,  1.03264772,  0.40003381,\n",
      "        0.39390374,  0.88947242, -0.1036063 ,  0.00304282,  1.00450758,\n",
      "        0.0383625 ,  0.09619601,  0.14190294, -0.02098554, -0.11779705]), array([ 0.40277401,  0.40924345, -0.00252409,  1.01167358,  0.40590534,\n",
      "        0.39785021,  0.86369569, -0.10896417,  0.00262072,  1.04136045,\n",
      "        0.00523897,  0.0837748 ,  0.08073715, -0.0398471 , -0.09151708]), array([ 3.98604610e-01,  4.01478858e-01, -3.04554147e-04,  1.01686858e+00,\n",
      "        4.00692933e-01,  3.91754448e-01,  8.65179730e-01, -1.08728054e-01,\n",
      "       -1.97922001e-03,  1.05066576e+00,  1.28647761e-02,  8.87918537e-02,\n",
      "        8.00012196e-02, -4.55273760e-02, -9.33398663e-02]), array([ 0.40000302,  0.40795225, -0.00168516,  1.01838289,  0.40426707,\n",
      "        0.39868031,  0.86600171, -0.10881444, -0.00187482,  1.05173761,\n",
      "        0.0097454 ,  0.08486194,  0.07845383, -0.04537372, -0.09359557]), array([ 0.39856627,  0.403124  , -0.00462852,  1.02352845,  0.39904372,\n",
      "        0.39621763,  0.85737281, -0.10290729,  0.0024112 ,  1.05861992,\n",
      "        0.01211857,  0.06117995,  0.08222809, -0.05183356, -0.09086124]), array([ 4.00938627e-01,  3.96463343e-01, -2.79986992e-03,  1.02888700e+00,\n",
      "        4.02039010e-01,  3.97739159e-01,  8.70925463e-01, -1.04667740e-01,\n",
      "        1.04202368e-03,  1.04661471e+00,  1.90173602e-02,  7.29005335e-02,\n",
      "        8.53747940e-02, -5.03942630e-02, -9.58807104e-02]), array([ 0.40055771,  0.40085023, -0.00367756,  1.02397297,  0.39910275,\n",
      "        0.39560887,  0.86302847, -0.10402075,  0.00168461,  1.04723426,\n",
      "        0.01694402,  0.06788763,  0.08335897, -0.04850918, -0.09429216]), array([ 0.4010432 ,  0.3996049 , -0.00192605,  1.02277352,  0.4000177 ,\n",
      "        0.39883738,  0.86392217, -0.10310446,  0.00106976,  1.04577583,\n",
      "        0.01473931,  0.07200999,  0.08531581, -0.04879091, -0.09316951]), array([ 4.01013132e-01,  3.99424519e-01, -1.70915351e-03,  1.02314710e+00,\n",
      "        3.99663862e-01,  3.98499802e-01,  8.63736857e-01, -1.03630469e-01,\n",
      "       -2.59668134e-04,  1.04526902e+00,  1.59682801e-02,  7.26345047e-02,\n",
      "        8.59964832e-02, -4.91030190e-02, -9.36371043e-02]), array([ 0.39796872,  0.40169006, -0.00249709,  1.02261162,  0.39763599,\n",
      "        0.39686033,  0.8595125 , -0.10433447, -0.00138016,  1.05150463,\n",
      "        0.01691673,  0.0675    ,  0.08235673, -0.0504672 , -0.09444968]), array([ 3.98224983e-01,  3.98804229e-01, -2.99619467e-03,  1.01789691e+00,\n",
      "        3.97919399e-01,  3.96956218e-01,  8.57831355e-01, -1.04725354e-01,\n",
      "        8.46661518e-04,  1.04414249e+00,  1.57579271e-02,  6.86391192e-02,\n",
      "        8.11411622e-02, -4.57133824e-02, -9.36808194e-02]), array([ 0.40020664,  0.39850256, -0.00134383,  1.02052112,  0.39847843,\n",
      "        0.39874091,  0.86097354, -0.10407548, -0.00144788,  1.0434927 ,\n",
      "        0.01633313,  0.07326086,  0.08525876, -0.04775141, -0.09356518]), array([ 3.97980386e-01,  3.97458667e-01, -8.01120406e-05,  1.01666481e+00,\n",
      "        3.94596638e-01,  3.91802581e-01,  8.58914202e-01, -1.03935731e-01,\n",
      "       -2.74502949e-03,  1.04381451e+00,  2.03902904e-02,  7.18923187e-02,\n",
      "        8.53297943e-02, -4.87555681e-02, -9.69126351e-02]), array([ 0.40343287,  0.40802843, -0.0031964 ,  1.03182532,  0.40234333,\n",
      "        0.40136513,  0.86715357, -0.1028953 ,  0.00357998,  1.05842159,\n",
      "        0.00998236,  0.06264933,  0.08666374, -0.04366708, -0.09136907]), array([ 0.40661104,  0.40194666, -0.00306589,  1.03691992,  0.40345932,\n",
      "        0.40130448,  0.87619335, -0.10309555,  0.0034613 ,  1.05172915,\n",
      "        0.01552046,  0.06903908,  0.0891163 , -0.04311556, -0.0934508 ]), array([ 0.40066635,  0.3972306 , -0.00120112,  1.0204991 ,  0.39509271,\n",
      "        0.39535393,  0.8615092 , -0.096915  , -0.00398122,  1.05356543,\n",
      "        0.0100019 ,  0.06123327,  0.08231904, -0.04439211, -0.09369967]), array([ 0.39989585,  0.40410218,  0.00112538,  1.02382483,  0.39760514,\n",
      "        0.39372083,  0.86217303, -0.10170979,  0.00202188,  1.0576618 ,\n",
      "        0.01456595,  0.06347018,  0.08377616, -0.04770249, -0.09596245]), array([ 4.03410430e-01,  4.01111194e-01, -7.27696666e-04,  1.03013269e+00,\n",
      "        3.98436858e-01,  3.97782274e-01,  8.68505145e-01, -1.01452697e-01,\n",
      "        7.50489216e-04,  1.05571807e+00,  1.78376452e-02,  6.59844182e-02,\n",
      "        8.26558879e-02, -4.56432569e-02, -9.50324941e-02]), array([ 0.40453623,  0.40572555, -0.00450965,  1.03367604,  0.40524632,\n",
      "        0.4031076 ,  0.86793917, -0.10863536,  0.00168245,  1.05008876,\n",
      "        0.01355011,  0.07248273,  0.09384443, -0.04527993, -0.09638132]), array([ 4.03878178e-01,  3.99148503e-01, -8.15291502e-05,  1.03008391e+00,\n",
      "        3.99145978e-01,  3.97089283e-01,  8.69300470e-01, -1.01756806e-01,\n",
      "       -1.57572718e-03,  1.06252560e+00,  1.15439627e-02,  6.70863195e-02,\n",
      "        8.19589458e-02, -4.86816462e-02, -9.37855203e-02]), array([ 3.99466156e-01,  4.02088057e-01, -2.48042630e-04,  1.01652302e+00,\n",
      "        3.94160573e-01,  3.96460528e-01,  8.56591198e-01, -1.02205812e-01,\n",
      "       -1.06288161e-03,  1.05157798e+00,  1.53943167e-02,  6.20703153e-02,\n",
      "        7.93536044e-02, -4.17753487e-02, -9.37351235e-02]), array([ 0.40101383,  0.40461237, -0.00209727,  1.02555352,  0.39996522,\n",
      "        0.39974513,  0.85947431, -0.10703092, -0.00118395,  1.05342026,\n",
      "        0.01550819,  0.06945011,  0.08702076, -0.04713019, -0.09773345]), array([ 0.40220703,  0.40166084, -0.00347445,  1.02796806,  0.401818  ,\n",
      "        0.40180568,  0.86083294, -0.11087425, -0.00140368,  1.05035904,\n",
      "        0.01532569,  0.07132785,  0.09221323, -0.0438787 , -0.09732961]), array([ 3.98560610e-01,  3.97253197e-01, -7.52230131e-04,  1.01958129e+00,\n",
      "        3.98603885e-01,  4.00609698e-01,  8.59020944e-01, -1.11091520e-01,\n",
      "       -4.71665745e-03,  1.05175258e+00,  1.61554518e-02,  6.84720045e-02,\n",
      "        9.02937294e-02, -4.60109021e-02, -9.53452605e-02]), array([ 0.40048576,  0.40178345, -0.00111488,  1.02017236,  0.39881849,\n",
      "        0.4001514 ,  0.85300908, -0.11176771, -0.00190926,  1.046328  ,\n",
      "        0.01730861,  0.07312582,  0.08617097, -0.04150408, -0.09617837]), array([ 3.97419698e-01,  4.04568290e-01, -4.55911718e-04,  1.01073240e+00,\n",
      "        3.98373463e-01,  4.01762559e-01,  8.39607475e-01, -1.08056994e-01,\n",
      "       -2.34633942e-03,  1.04394426e+00,  1.50909880e-02,  6.92334412e-02,\n",
      "        7.80751740e-02, -3.27488305e-02, -9.51027605e-02]), array([ 0.39358384,  0.39639593,  0.00398793,  0.99808408,  0.39273699,\n",
      "        0.39480425,  0.83936844, -0.10769642, -0.00372092,  1.04014288,\n",
      "        0.02047672,  0.06891605,  0.07859933, -0.03704761, -0.09745749]), array([ 3.96763264e-01,  4.01810968e-01, -3.08154836e-03,  1.01320316e+00,\n",
      "        3.98807136e-01,  3.99311120e-01,  8.38571469e-01, -1.07833381e-01,\n",
      "        4.38056516e-04,  1.04921005e+00,  1.61453832e-02,  6.48243697e-02,\n",
      "        7.60363976e-02, -3.34031362e-02, -9.46982425e-02]), array([ 0.39409284,  0.3950356 ,  0.00248304,  1.00079146,  0.39061636,\n",
      "        0.40082913,  0.83434387, -0.10696221, -0.00966953,  1.03660162,\n",
      "        0.02285588,  0.06788804,  0.07892387, -0.03435247, -0.09720202]), array([ 0.39093208,  0.3887396 ,  0.00116686,  0.99210898,  0.38754618,\n",
      "        0.39366263,  0.8284451 , -0.10716903, -0.00643928,  1.04796842,\n",
      "        0.01827702,  0.05595818,  0.07183041, -0.04051227, -0.09379109]), array([ 3.91454229e-01,  3.95007976e-01, -3.76176473e-05,  1.00540565e+00,\n",
      "        3.91223459e-01,  3.99840135e-01,  8.28644483e-01, -1.04725600e-01,\n",
      "       -2.59948594e-03,  1.04205724e+00,  2.19080248e-02,  6.37275075e-02,\n",
      "        7.19585569e-02, -3.24924641e-02, -9.56414543e-02]), array([ 3.93664813e-01,  4.03431015e-01, -4.44732040e-04,  9.97804766e-01,\n",
      "        3.98608559e-01,  4.02990443e-01,  8.26781817e-01, -1.12712954e-01,\n",
      "       -3.68344434e-03,  1.03789471e+00,  1.89493605e-02,  6.80354326e-02,\n",
      "        8.16403878e-02, -3.32112356e-02, -9.89401495e-02]), array([ 3.90851506e-01,  4.00128937e-01, -9.13361871e-04,  9.98944162e-01,\n",
      "        3.98153495e-01,  4.01059936e-01,  8.25164808e-01, -1.11019052e-01,\n",
      "       -5.70474846e-03,  1.04690743e+00,  1.80126717e-02,  6.47807697e-02,\n",
      "        7.98932219e-02, -3.41786321e-02, -9.79604527e-02]), array([ 3.91767255e-01,  4.00257463e-01, -7.94730515e-04,  1.00902502e+00,\n",
      "        4.01178763e-01,  4.04102620e-01,  8.29300734e-01, -1.08873724e-01,\n",
      "       -1.16085359e-03,  1.04769281e+00,  1.74223328e-02,  6.95698600e-02,\n",
      "        7.81872109e-02, -3.24498567e-02, -9.75426780e-02]), array([ 4.07168741e-01,  4.19275806e-01, -9.73894331e-04,  1.00397755e+00,\n",
      "        3.97848304e-01,  4.03148668e-01,  8.17804755e-01, -1.29666202e-01,\n",
      "        2.90550257e-03,  1.03942871e+00,  1.48837888e-02,  6.61815903e-02,\n",
      "        8.30699867e-02, -1.93703770e-02, -9.15843946e-02]), array([ 0.3978629 ,  0.40463464, -0.00129493,  1.00101141,  0.39963329,\n",
      "        0.40423177,  0.81349657, -0.12080853, -0.00417795,  1.04578059,\n",
      "        0.02157664,  0.06430961,  0.08003836, -0.02498213, -0.10218361]), array([ 3.96948577e-01,  4.06892217e-01, -1.84984428e-03,  1.00452426e+00,\n",
      "        3.98931276e-01,  4.04929739e-01,  8.10196807e-01, -1.16150676e-01,\n",
      "        8.90741022e-04,  1.04572774e+00,  1.80036792e-02,  6.31500169e-02,\n",
      "        7.66976188e-02, -2.15988990e-02, -9.98291362e-02]), array([ 0.4043451 ,  0.4141692 , -0.00387614,  0.9604987 ,  0.40188376,\n",
      "        0.40587837,  0.76710339, -0.14405471, -0.00579458,  1.02958541,\n",
      "        0.00166551,  0.05521167,  0.07883376,  0.01796988, -0.10174382]), array([ 0.39404223,  0.39846054, -0.00316552,  0.95982805,  0.4013147 ,\n",
      "        0.39833072,  0.76157998, -0.13885426, -0.00739938,  1.03428058,\n",
      "        0.00384717,  0.05465218,  0.08672382,  0.01530494, -0.11024473]), array([ 0.39380999,  0.40083757, -0.0017818 ,  0.9667104 ,  0.4007023 ,\n",
      "        0.39940784,  0.76333525, -0.14131746, -0.00399121,  1.0390515 ,\n",
      "        0.00457782,  0.05403814,  0.07850956,  0.01220343, -0.10802614])]\n",
      "reward: 1551.5009107468125\n"
     ]
    }
   ],
   "source": [
    "dummy_states, dummy_actions, dummy_reward = generate_session(env, agent, t_max=100)\n",
    "print(\"states:\", np.stack(dummy_states))\n",
    "print(\"actions:\", dummy_actions)\n",
    "print(\"reward:\", dummy_reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p85lt16qG9zL"
   },
   "source": [
    "### CEM steps\n",
    "Deep CEM uses exactly the same strategy as the regular CEM, so you can copy your function code from previous notebook.\n",
    "\n",
    "The only difference is that now each observation is not a number but a `float32` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4On-p7p4G9zL"
   },
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order\n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you are confused, see examples below. Please don't assume that states are integers\n",
    "    (they will become different later).\n",
    "    \"\"\"\n",
    "    debug = False\n",
    "    if debug:\n",
    "        print(\"states_batch \",states_batch)\n",
    "        print(\"actions_batch \",actions_batch)\n",
    "        print(\"rewards_batch \",rewards_batch)\n",
    "        print(\"percentile \",percentile)\n",
    "    \n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "    if debug:\n",
    "        print(\"reward_threshold \", reward_threshold)\n",
    "\n",
    "    reward_select = np.zeros_like(rewards_batch)\n",
    "    reward_select[rewards_batch >= reward_threshold] = 1\n",
    "    if debug:\n",
    "        print(\"reward_select \", reward_select)\n",
    "\n",
    "    elite_states = []\n",
    "    elite_actions = []\n",
    "\n",
    "    for index, item in enumerate(reward_select):\n",
    "        if item:\n",
    "            elite_states.extend(states_batch[index])\n",
    "            elite_actions.extend(actions_batch[index])\n",
    "\n",
    "    if debug:\n",
    "        print(\"elite_states \", elite_states)\n",
    "        print(\"elite_actions \", elite_actions)\n",
    "\n",
    "    return elite_states, elite_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "states_batch = [\n",
    "    [[-0.1, -0.1,  0.1,  0.1],\n",
    "    [-0.2, -0.2,  0.2,  0.2],\n",
    "    [-0.3,  -0.3,  0.3,  0.3 ],\n",
    "    [-0.4, -0.4,   0.4,  0.4  ],\n",
    "    [-0.5, -0.5,  0.5,  0.5 ]] ,  # game1\n",
    "    \n",
    "    [[-1.1, -0.1,  0.1,  0.1],\n",
    "    [-1.2, -0.2,  0.2,  0.2],\n",
    "    [-1.3,  -0.3,  0.3,  0.3 ],\n",
    "    [-1.4, -0.4,   0.4,  0.4  ],\n",
    "    [-1.5, -0.5,  0.5,  0.5 ]] ,  # game2\n",
    "        \n",
    "    [[-2.1, -0.1,  0.1,  0.1],\n",
    "    [-2.2, -0.2,  0.2,  0.2],\n",
    "    [-2.3,  -0.3,  0.3,  0.3 ]],   # game3\n",
    "]\n",
    "\n",
    "actions_batch = [\n",
    "    [0, 0, 0, 0, 1],     # game1\n",
    "    [0, 1, 0, 1, 1],  # game2\n",
    "    [0, 0, 0],        # game3\n",
    "]\n",
    "rewards_batch = [\n",
    "    5.0,  # game1\n",
    "    5.0,  # game2\n",
    "    3.0,  # game3\n",
    "]\n",
    "\n",
    "test_result_0 = select_elites(states_batch, actions_batch, rewards_batch, percentile=0)\n",
    "test_result_30 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=30\n",
    ")\n",
    "test_result_100 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=100\n",
    ")\n",
    "\n",
    "assert np.all(\n",
    "    test_result_0[0] == [\n",
    "    [-0.1, -0.1,  0.1,  0.1],\n",
    "    [-0.2, -0.2,  0.2,  0.2],\n",
    "    [-0.3,  -0.3,  0.3,  0.3 ],\n",
    "    [-0.4, -0.4,   0.4,  0.4  ],\n",
    "    [-0.5, -0.5,  0.5,  0.5 ]\n",
    "    ,\n",
    "    [-1.1, -0.1,  0.1,  0.1],\n",
    "    [-1.2, -0.2,  0.2,  0.2],\n",
    "    [-1.3,  -0.3,  0.3,  0.3 ],\n",
    "    [-1.4, -0.4,   0.4,  0.4  ],\n",
    "    [-1.5, -0.5,  0.5,  0.5 ]\n",
    "    ,\n",
    "    [-2.1, -0.1,  0.1,  0.1],\n",
    "    [-2.2, -0.2,  0.2,  0.2],\n",
    "    [-2.3,  -0.3,  0.3,  0.3 ]\n",
    "    ]\n",
    "    and test_result_0[1] == [\n",
    "        0, 0, 0, 0, 1,     # game1\n",
    "        0, 1, 0, 1, 1,  # game2\n",
    "        0, 0, 0   # game2\n",
    "    ]\n",
    "), \"For percentile 0 you should return all states and actions in chronological order\"\n",
    "\n",
    "\n",
    "assert np.all(\n",
    "    test_result_30[0] == [\n",
    "    [-0.1, -0.1,  0.1,  0.1],\n",
    "    [-0.2, -0.2,  0.2,  0.2],\n",
    "    [-0.3,  -0.3,  0.3,  0.3 ],\n",
    "    [-0.4, -0.4,   0.4,  0.4  ],\n",
    "    [-0.5, -0.5,  0.5,  0.5 ]\n",
    "    ,\n",
    "    [-1.1, -0.1,  0.1,  0.1],\n",
    "    [-1.2, -0.2,  0.2,  0.2],\n",
    "    [-1.3,  -0.3,  0.3,  0.3 ],\n",
    "    [-1.4, -0.4,   0.4,  0.4  ],\n",
    "    [-1.5, -0.5,  0.5,  0.5 ]\n",
    "    ]\n",
    "    and test_result_30[1] == [\n",
    "        0, 0, 0, 0, 1,     # game1\n",
    "        0, 1, 0, 1, 1  # game2\n",
    "    ]\n",
    "), \"For percentile 30 you should only select states/actions from two first\"\n",
    "\n",
    "assert np.all(\n",
    "    test_result_100[0] == [\n",
    "    [-0.1, -0.1,  0.1,  0.1],\n",
    "    [-0.2, -0.2,  0.2,  0.2],\n",
    "    [-0.3,  -0.3,  0.3,  0.3 ],\n",
    "    [-0.4, -0.4,   0.4,  0.4  ],\n",
    "    [-0.5, -0.5,  0.5,  0.5 ]\n",
    "    ,\n",
    "    [-1.1, -0.1,  0.1,  0.1],\n",
    "    [-1.2, -0.2,  0.2,  0.2],\n",
    "    [-1.3,  -0.3,  0.3,  0.3 ],\n",
    "    [-1.4, -0.4,   0.4,  0.4  ],\n",
    "    [-1.5, -0.5,  0.5,  0.5 ]\n",
    "    ]\n",
    "    and test_result_100[1] == [\n",
    "        0, 0, 0, 0, 1,     # game1\n",
    "        0, 1, 0, 1, 1  # game2\n",
    "    ]\n",
    "), \"Please make sure you use >=, not >. Also double-check how you compute percentile.\"\n",
    "\n",
    "print(\"Ok!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xc40V4DaG9zM"
   },
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PPwVKwF7G9zM"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress.\n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    print(\"date %s\" % (datetime.now()))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label=\"Mean rewards\")\n",
    "    plt.plot(list(zip(*log))[1], label=\"Reward thresholds\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines(\n",
    "        [np.percentile(rewards_batch, percentile)],\n",
    "        [0],\n",
    "        [100],\n",
    "        label=\"percentile\",\n",
    "        color=\"red\",\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeNWKjtsG9zM"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = 559.045, threshold=63.136\n",
      "date 2023-08-30 10:02:41.799167\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Win! You may stop training now via KeyboardInterrupt.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "n_sessions = 20\n",
    "percentile = 60\n",
    "log = []\n",
    "\n",
    "for i in range(150):\n",
    "    # generate new sessions\n",
    "    sessions = [ generate_session(env, agent, t_max=1000) for _ in range(n_sessions) ]\n",
    "\n",
    "    if False:\n",
    "        pprint(sessions)\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = map(list, zip(*sessions))\n",
    "    if False:\n",
    "        print(states_batch.shape)\n",
    "        print(actions_batch.shape)\n",
    "        print(rewards_batch.shape)\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "\n",
    "    if True:\n",
    "        print(elite_states)\n",
    "        print(elite_actions)\n",
    "    \n",
    "    #for a in elite_actions:\n",
    "    #     a[2] = 0\n",
    "    #     a[8] = 0\n",
    "    #     a[0] = 0.4\n",
    "    #     a[1] = 0.4\n",
    "    #     a[5] = 0.4\n",
    "    #     a[4] = 0.4\n",
    "\n",
    "    # <YOUR CODE: partial_fit agent to predict elite_actions(y) from elite_states(X)>\n",
    "    agent.partial_fit(elite_states, elite_actions)\n",
    "    # save model\n",
    "    joblib.dump(agent, filename)\n",
    "\n",
    "    show_progress(\n",
    "         rewards_batch, log, percentile, reward_range=[np.min(rewards_batch), np.max(rewards_batch)]\n",
    "    )\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RJwsWl4kG9zM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luc/Library/Python/3.11/lib/python/site-packages/gymnasium/envs/registration.py:513: DeprecationWarning: \u001B[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001B[0m\n",
      "  logger.deprecation(\n",
      "/Users/luc/Library/Python/3.11/lib/python/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001B[33mWARN: Overwriting existing videos at /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001B[0m\n",
      "  logger.warn(\n",
      "/Users/luc/Library/Python/3.11/lib/python/site-packages/gymnasium/core.py:297: UserWarning: \u001B[33mWARN: env.is_vector_env to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_vector_env` for environment variables or `env.get_attr('is_vector_env')` that will search the reminding wrappers.\u001B[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-0.mp4\n",
      "Moviepy - Building video /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-1.mp4.\n",
      "Moviepy - Writing video /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-1.mp4\n",
      "Moviepy - Building video /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-2.mp4.\n",
      "Moviepy - Writing video /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-2.mp4\n",
      "Moviepy - Building video /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-3.mp4.\n",
      "Moviepy - Writing video /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-3.mp4\n",
      "Moviepy - Building video /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-4.mp4.\n",
      "Moviepy - Writing video /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/luc/Projects/rl/Practical Reinforcement Learning/Practical_RL/week01_intro/videos/rl-video-episode-4.mp4\n"
     ]
    }
   ],
   "source": [
    "# Record sessions\n",
    "\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "with RecordVideo(\n",
    "    env=gym.make(\"CartPole-v0\", render_mode=\"rgb_array\", max_episode_steps=10000),\n",
    "    video_folder=\"./videos\",\n",
    "    episode_trigger=lambda episode_number: True,\n",
    "    video_length=0\n",
    ") as env_monitor:\n",
    "    sessions = [generate_session(env_monitor, agent,100000) for _ in range(5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLPXdME7G9zN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"videos/rl-video-episode-9.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from base64 import b64encode\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_paths = sorted([s for s in Path(\"videos\").iterdir() if s.suffix == \".mp4\"])\n",
    "video_path = video_paths[-1]  # You can also try other indices\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # https://stackoverflow.com/a/57378660/1214547\n",
    "    with video_path.open(\"rb\") as fp:\n",
    "        mp4 = fp.read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "else:\n",
    "    data_url = str(video_path)\n",
    "\n",
    "HTML(\n",
    "    \"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\n",
    "        data_url\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d_3oOQ1G9zN"
   },
   "source": [
    "# Homework part I\n",
    "\n",
    "### Tabular crossentropy method\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from -100 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
    "\n",
    "### Tasks\n",
    "- __1.1__ (2 pts) Find out how the algorithm performance changes if you use a different `percentile` and/or `n_sessions`. Provide here some figures so we can see how the hyperparameters influence the performance.\n",
    "- __1.2__ (1 pts) Tune the algorithm to end up with positive average score.\n",
    "\n",
    "It's okay to modify the existing code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L88LySiVG9zN"
   },
   "source": [
    "```<Describe what you did here>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LpAJc4rG9zN"
   },
   "source": [
    "# Homework part II\n",
    "\n",
    "### Deep crossentropy method\n",
    "\n",
    "By this moment, you should have got enough score on [CartPole-v0](https://gymnasium.farama.org/environments/classic_control/cart_pole/) to consider it solved (see the link). It's time to try something harder.\n",
    "\n",
    "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* __2.1__ (3 pts) Pick one of environments: `MountainCar-v0` or `LunarLander-v2`.\n",
    "  * For MountainCar, get average reward of __at least -150__\n",
    "  * For LunarLander, get average reward of __at least +50__\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "__Note:__ If your agent is below the target score, you'll still get some of the points depending on the result, so don't be afraid to submit it.\n",
    "  \n",
    "  \n",
    "* __2.2__ (up to 6 pts) Devise a way to speed up training against the default version\n",
    "  * Obvious improvement: use [`joblib`](https://joblib.readthedocs.io/en/latest/). However, note that you will probably need to spawn a new environment in each of the workers instead of passing it via pickling. (2 pts)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training. (2 pts)\n",
    "  * Obtain __-100__ at `MountainCar-v0` or __+200__ at `LunarLander-v2` (2 pts). Feel free to experiment with hyperparameters, architectures, schedules etc.\n",
    "  \n",
    "__Please list what you did in Anytask submission form__. This reduces probability that somebody misses something.\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gymnasium pages: [MountainCar](https://gymnasium.farama.org/environments/classic_control/mountain_car/), [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 10% are better, than if you use percentile 20% as threshold, R >= threshold __fails to cut off bad sessions__ while R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
    "* If it doesn't train, it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "\n",
    "You may find the following snippet useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qcjz-nm_G9zN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luc/Library/Python/3.11/lib/python/site-packages/gymnasium/envs/registration.py:788: UserWarning: \u001B[33mWARN: The environment is being initialised with render_mode='rgb_arrary' that is not in the possible render_modes (['human', 'rgb_array']).\u001B[0m\n",
      "  logger.warn(\n",
      "/Users/luc/Library/Python/3.11/lib/python/site-packages/gymnasium/core.py:297: UserWarning: \u001B[33mWARN: env.min_position to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.min_position` for environment variables or `env.get_attr('min_position')` that will search the reminding wrappers.\u001B[0m\n",
      "  logger.warn(\n",
      "/Users/luc/Library/Python/3.11/lib/python/site-packages/gymnasium/core.py:297: UserWarning: \u001B[33mWARN: env.max_position to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.max_position` for environment variables or `env.get_attr('max_position')` that will search the reminding wrappers.\u001B[0m\n",
      "  logger.warn(\n",
      "/Users/luc/Library/Python/3.11/lib/python/site-packages/gymnasium/core.py:297: UserWarning: \u001B[33mWARN: env.max_speed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.max_speed` for environment variables or `env.get_attr('max_speed')` that will search the reminding wrappers.\u001B[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2 features, but MLPClassifier is expecting 4 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 43\u001B[0m\n\u001B[1;32m     39\u001B[0m             plt\u001B[39m.\u001B[39marrow(x, v, \u001B[39m0.1\u001B[39m, \u001B[39m0\u001B[39m, color\u001B[39m=\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mwhite\u001B[39m\u001B[39m\"\u001B[39m, head_length\u001B[39m=\u001B[39m\u001B[39m0.02\u001B[39m)\n\u001B[1;32m     42\u001B[0m \u001B[39mwith\u001B[39;00m gym\u001B[39m.\u001B[39mmake(\u001B[39m\"\u001B[39m\u001B[39mMountainCar-v0\u001B[39m\u001B[39m\"\u001B[39m, render_mode\u001B[39m=\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mrgb_arrary\u001B[39m\u001B[39m\"\u001B[39m)\u001B[39m.\u001B[39menv \u001B[39mas\u001B[39;00m env:\n\u001B[0;32m---> 43\u001B[0m     visualize_mountain_car(env, agent)\n",
      "Cell \u001B[0;32mIn[12], line 9\u001B[0m, in \u001B[0;36mvisualize_mountain_car\u001B[0;34m(env, agent)\u001B[0m\n\u001B[1;32m      6\u001B[0m grid \u001B[39m=\u001B[39m np\u001B[39m.\u001B[39mdstack(np\u001B[39m.\u001B[39mmeshgrid(xs, vs[::\u001B[39m-\u001B[39m\u001B[39m1\u001B[39m]))\u001B[39m.\u001B[39mtranspose(\u001B[39m1\u001B[39m, \u001B[39m0\u001B[39m, \u001B[39m2\u001B[39m)\n\u001B[1;32m      7\u001B[0m grid_flat \u001B[39m=\u001B[39m grid\u001B[39m.\u001B[39mreshape(\u001B[39mlen\u001B[39m(xs) \u001B[39m*\u001B[39m \u001B[39mlen\u001B[39m(vs), \u001B[39m2\u001B[39m)\n\u001B[1;32m      8\u001B[0m probs \u001B[39m=\u001B[39m (\n\u001B[0;32m----> 9\u001B[0m     agent\u001B[39m.\u001B[39;49mpredict_proba(grid_flat)\u001B[39m.\u001B[39mreshape(\u001B[39mlen\u001B[39m(xs), \u001B[39mlen\u001B[39m(vs), \u001B[39m3\u001B[39m)\u001B[39m.\u001B[39mtranspose(\u001B[39m1\u001B[39m, \u001B[39m0\u001B[39m, \u001B[39m2\u001B[39m)\n\u001B[1;32m     10\u001B[0m )\n\u001B[1;32m     12\u001B[0m \u001B[39m# # The above code is equivalent to the following:\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[39m# probs = np.empty((len(vs), len(xs), 3))\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[39m# for i, v in enumerate(vs[::-1]):\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m \n\u001B[1;32m     18\u001B[0m \u001B[39m# Draw policy\u001B[39;00m\n\u001B[1;32m     19\u001B[0m f, ax \u001B[39m=\u001B[39m plt\u001B[39m.\u001B[39msubplots(figsize\u001B[39m=\u001B[39m(\u001B[39m7\u001B[39m, \u001B[39m7\u001B[39m))\n",
      "File \u001B[0;32m~/Library/Python/3.11/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1244\u001B[0m, in \u001B[0;36mMLPClassifier.predict_proba\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m   1230\u001B[0m \u001B[39m\u001B[39m\u001B[39m\"\"\"Probability estimates.\u001B[39;00m\n\u001B[1;32m   1231\u001B[0m \n\u001B[1;32m   1232\u001B[0m \u001B[39mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1241\u001B[0m \u001B[39m    model, where classes are ordered as they are in `self.classes_`.\u001B[39;00m\n\u001B[1;32m   1242\u001B[0m \u001B[39m\"\"\"\u001B[39;00m\n\u001B[1;32m   1243\u001B[0m check_is_fitted(\u001B[39mself\u001B[39m)\n\u001B[0;32m-> 1244\u001B[0m y_pred \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_forward_pass_fast(X)\n\u001B[1;32m   1246\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mn_outputs_ \u001B[39m==\u001B[39m \u001B[39m1\u001B[39m:\n\u001B[1;32m   1247\u001B[0m     y_pred \u001B[39m=\u001B[39m y_pred\u001B[39m.\u001B[39mravel()\n",
      "File \u001B[0;32m~/Library/Python/3.11/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:207\u001B[0m, in \u001B[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001B[0;34m(self, X, check_input)\u001B[0m\n\u001B[1;32m    188\u001B[0m \u001B[39m\u001B[39m\u001B[39m\"\"\"Predict using the trained model\u001B[39;00m\n\u001B[1;32m    189\u001B[0m \n\u001B[1;32m    190\u001B[0m \u001B[39mThis is the same as _forward_pass but does not record the activations\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    204\u001B[0m \u001B[39m    The decision function of the samples for each class in the model.\u001B[39;00m\n\u001B[1;32m    205\u001B[0m \u001B[39m\"\"\"\u001B[39;00m\n\u001B[1;32m    206\u001B[0m \u001B[39mif\u001B[39;00m check_input:\n\u001B[0;32m--> 207\u001B[0m     X \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_validate_data(X, accept_sparse\u001B[39m=\u001B[39;49m[\u001B[39m\"\u001B[39;49m\u001B[39mcsr\u001B[39;49m\u001B[39m\"\u001B[39;49m, \u001B[39m\"\u001B[39;49m\u001B[39mcsc\u001B[39;49m\u001B[39m\"\u001B[39;49m], reset\u001B[39m=\u001B[39;49m\u001B[39mFalse\u001B[39;49;00m)\n\u001B[1;32m    209\u001B[0m \u001B[39m# Initialize first layer\u001B[39;00m\n\u001B[1;32m    210\u001B[0m activation \u001B[39m=\u001B[39m X\n",
      "File \u001B[0;32m~/Library/Python/3.11/lib/python/site-packages/sklearn/base.py:625\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[1;32m    622\u001B[0m     out \u001B[39m=\u001B[39m X, y\n\u001B[1;32m    624\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m no_val_X \u001B[39mand\u001B[39;00m check_params\u001B[39m.\u001B[39mget(\u001B[39m\"\u001B[39m\u001B[39mensure_2d\u001B[39m\u001B[39m\"\u001B[39m, \u001B[39mTrue\u001B[39;00m):\n\u001B[0;32m--> 625\u001B[0m     \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_check_n_features(X, reset\u001B[39m=\u001B[39;49mreset)\n\u001B[1;32m    627\u001B[0m \u001B[39mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/Library/Python/3.11/lib/python/site-packages/sklearn/base.py:414\u001B[0m, in \u001B[0;36mBaseEstimator._check_n_features\u001B[0;34m(self, X, reset)\u001B[0m\n\u001B[1;32m    411\u001B[0m     \u001B[39mreturn\u001B[39;00m\n\u001B[1;32m    413\u001B[0m \u001B[39mif\u001B[39;00m n_features \u001B[39m!=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mn_features_in_:\n\u001B[0;32m--> 414\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(\n\u001B[1;32m    415\u001B[0m         \u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mX has \u001B[39m\u001B[39m{\u001B[39;00mn_features\u001B[39m}\u001B[39;00m\u001B[39m features, but \u001B[39m\u001B[39m{\u001B[39;00m\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m\u001B[39m__class__\u001B[39m\u001B[39m.\u001B[39m\u001B[39m__name__\u001B[39m\u001B[39m}\u001B[39;00m\u001B[39m \u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m    416\u001B[0m         \u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mis expecting \u001B[39m\u001B[39m{\u001B[39;00m\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mn_features_in_\u001B[39m}\u001B[39;00m\u001B[39m features as input.\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m    417\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: X has 2 features, but MLPClassifier is expecting 4 features as input."
     ]
    }
   ],
   "source": [
    "def visualize_mountain_car(env, agent):\n",
    "    # Compute policy for all possible x and v (with discretization)\n",
    "    xs = np.linspace(env.min_position, env.max_position, 100)\n",
    "    vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
    "\n",
    "    grid = np.dstack(np.meshgrid(xs, vs[::-1])).transpose(1, 0, 2)\n",
    "    grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
    "    probs = (\n",
    "        agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3).transpose(1, 0, 2)\n",
    "    )\n",
    "\n",
    "    # # The above code is equivalent to the following:\n",
    "    # probs = np.empty((len(vs), len(xs), 3))\n",
    "    # for i, v in enumerate(vs[::-1]):\n",
    "    #     for j, x in enumerate(xs):\n",
    "    #         probs[i, j, :] = agent.predict_proba([[x, v]])[0]\n",
    "\n",
    "    # Draw policy\n",
    "    f, ax = plt.subplots(figsize=(7, 7))\n",
    "    ax.imshow(\n",
    "        probs,\n",
    "        extent=(env.min_position, env.max_position, -env.max_speed, env.max_speed),\n",
    "        aspect=\"auto\",\n",
    "    )\n",
    "    ax.set_title(\"Learned policy: red=left, green=nothing, blue=right\")\n",
    "    ax.set_xlabel(\"position (x)\")\n",
    "    ax.set_ylabel(\"velocity (v)\")\n",
    "\n",
    "    # Sample a trajectory and draw it\n",
    "    states, actions, _ = generate_session(env, agent)\n",
    "    states = np.array(states)\n",
    "    ax.plot(states[:, 0], states[:, 1], color=\"white\")\n",
    "\n",
    "    # Draw every 3rd action from the trajectory\n",
    "    for (x, v), a in zip(states[::3], actions[::3]):\n",
    "        if a == 0:\n",
    "            plt.arrow(x, v, -0.1, 0, color=\"white\", head_length=0.02)\n",
    "        elif a == 2:\n",
    "            plt.arrow(x, v, 0.1, 0, color=\"white\", head_length=0.02)\n",
    "\n",
    "\n",
    "with gym.make(\"MountainCar-v0\", render_mode=\"rgb_arrary\").env as env:\n",
    "    visualize_mountain_car(env, agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dzk41lDPG9zO"
   },
   "source": [
    "### Bonus tasks\n",
    "\n",
    "* __2.3 bonus__ (2 pts) Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation. If you attempted this task, please mention it in Anytask submission._)\n",
    "\n",
    "* __2.4 bonus__ (4 pts) Solve continuous action space task with `MLPRegressor` or similar.\n",
    "  * Since your agent only predicts the \"expected\" action, you will have to add noise to ensure exploration.\n",
    "  * Choose one of [MountainCarContinuous-v0](https://gymnasium.farama.org/environments/classic_control/mountain_car_continuous/) (90+ pts to solve), [LunarLanderContinuous-v2](https://gymnasium.farama.org/environments/box2d/lunar_lander/) (`env = gym.make(\"LunarLander-v2\", continuous=True)`)(200+ pts to solve)\n",
    "  * 4 points for solving. Slightly less for getting some results below solution threshold. Note that discrete and continuous environments may have slightly different rules, aside from action spaces."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
